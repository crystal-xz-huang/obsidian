# 5.6 \[CR\] Cola Cables 

 
%% ![[COMP3121_9101-5.6.pdf#height=600]] %%

## Problem Description

This involves $n$ locations (*vertices*), and $m$ transmission cables (*edges*) that connect a distinct pair of locations as a graph $G= (V,E)$. Assume that messages can be sent in either direction across each cable (*undirected*). Due to a spill of off-brand Cola, each of the cables has a probability $p_i$ that a particular message will get through. You may assume that *all the probabilities are positive* (in particular, non-zero), so no cable is certain to fail. Further, you may assume that a path exists between any pair of distinct locations (*connected graph*).

A message is received at its destination if and only if it is not blocked by one of the transmission cables along the way. Note that all probabilities are independent.

- A connected undirected graph $G= (V,E)$ with $|V| = n$ locations and $|E| = m$ transmission cables. 
- Each "cable" (edge) connects two distinct "locations" (vertices) and has a transmission success probability $p_i \in (0, 1]$. 
- If the path $\pi$ uses edges $e_1, e_2, \dots, e_k$, the probability that message is received along this path to its destination is: $$P(\text{success on path } \pi)= p_1 \times p_2 \times \dots \times p_k= \prod_{e \in \pi} p(e)$$

 where $0 < p(e) \leq 1$. 

## Part (a)

> [!problem] 
> Thomas, being the energetic encoder that he is, prefers to look at *information* receiving rather than probability. Information in this context is defined as, for an event A, 
>
> $$I(A) = -\log_2 (p(A)),$$
>
> where $p(A)$ is the probability that event $A$ occurs. 
> 
> For example, the amount of information received for a message we are trying to send from $E15$ to $H13$ is  
>
> $$
> \begin{aligned}
> I(E15 \to H13) &= -\log_2 0.85 \\
> &\approx 0.2345
> \end{aligned}
> $$
>
> whereas the information from receiving a message from $K17$ to $H13$ is  
>
> $$
> \begin{aligned}
> I(K17 \to H13) &= -\log_2 0.6 \\
> &\approx 0.7370.
> \end{aligned}
> $$
>
> Note that the information that we get from $K17$ to $H13$ is larger because there is a higher probability of the message being blocked, so we are more surprised when we actually see something (i.e., it’s more *interesting* in the intuitive sense).
> 
> Calculate the information corresponding to sending a message from $F10$ to $E15$.

Information for an event $A$ with probability $p(A)$ is defined as 

$$I(A) = -\log_2 (p(A))$$

This comes from Information Theory — which measures how “surprising” the event is:
- If $p(A)$ is small → rare → high information (more surprising).
- If $p(A)$ is large → common → low information (less surprising).

From the example diagram, the probability that a message can travel from **F10 to E15** is given as

$$p(F10 \to E15) = 0.95$$

Therefore, plugging this in the Information formula:

$$
\begin{align*}
I(F10 \to E15)
&= -\log_2 (0.95) \\
&\approx 0.0740.
\end{align*}
$$

## Part B

> [!problem]
> Find the probability that a message can be successfully delivered from $K17$ to $H13$ to $E15$ to $F10$ via the blue path seen in the above diagram and use this to find the information of this event.

Probability of the whole path $K17 \to H13 \to E15 \to F10$:

- $p(K17 \to H13) = 0.6$
- $p(H13 \to E15) = 0.85$
- $p(E15 \to F10) = 0.95$

Since the transmission events across cables are independent, the probability that a message successfully travels from $K17$ to $H13$ to $E15$ to $F10$ is the product of the probabilities along each cable:

$$
\begin{align*}
p(K17 \to H13 \to E15 \to F10)
&= p(K17 \to H13) \times p(H13 \to E15) \times p(E15 \to F10) \\
&= 0.6 \times 0.85 \times 0.95 \\
&= 0.4845.
\end{align*}
$$

The information of this event is:

$$
\begin{align*}
I&= -\log_2(0.4845) \\
&\approx 1.0454.
\end{align*}
$$

## Part C

Compare your answer to (b) to the information found in (1), (2) and (a).

- (b) $I(K17 \to H13 \to E15 \to F10) = -\log_2 0.4845 \approx 1.0454.$
- (1) $I(E15\to H13) = -\log_2 0.85 \approx 0.2345.$
- (2) $I(K17\to H13) = -\log_2 0.6 \approx 0.7370.$
- (a) $I(F10 \to E15) = -\log_2 0.95 \approx 0.0740.$

Since the transmission events are independent, the total probability along the path is the product of the probabilities of each edge:

$$
p(K17 \to H13 \to E15 \to F10)
= p(K17 \to H13) \times p(H13 \to E15) \times p(E15 \to F10).
$$

Using the definition $I(A) = -\log_2 p(A)$ and the logarithmic identity

$$
\log(ab) = \log a + \log b,
$$

we have

$$
\begin{align*}
I(K17 \to H13 \to E15 \to F10)
&= -\log_2 (p_1 \ p_2 \ p_3) \\
&= -(\log_2 p_1 + \log_2 p_2 + \log_2 p_3) \\
&= I(K17 \to H13) + I(E15 \to H13) + I(F10 \to E15).
\end{align*}
$$

Hence, the total information of the path is the sum of the informations of its edges, which is equal to $1.0454$.

## Part D

> [!problem]
> Having been a part of ICCSOC for over 10 years, Thomas has always wanted to know the probability that a message will get through between any pair of distinct locations, assuming the best transmission strategy. That is, we are interested in the **highest transmission probability between every pair of vertices**, rather than the path itself.
>     
> By restating this problem in terms of information rather than probability, efficiently provide Thomas with the maximum probabilities between every pair of distinct locations by applying an established algorithm.   

---
- Define for every edge $e \in E$,  $\boxed{w(e)=−\log_2 p(e)}.$
- Recall that $\log x < 0 \iff x \in (0, 1)$ and that $\log x + \log y = \log(xy)$.
- Thus we have **non-negative weights** $\boxed{w(e)=−\log_2 p(e) \geq 0 \iff p(e) > 0}$
	- $w(e)=−\log_2 p(e) > 0 \iff 0 < p(e) < 1$. (positive weights)
	- $w(e)=−\log_2 p(e) = 0 \iff  p(e) = 1$. (zero weight when $p = 1$)

- The weight $w(\pi)$ of the path is then
$$
\begin{align*}
w(\pi) 
= p_1 \times p_2 \times \dots \times p_k
&= -\log_2 p_1 p_2 \dots p_k \\
&= -\log_2\prod_{i=1}^k p_i \\
&= -\sum_{i = 1}^k \log_2 p_i \quad (\text{since } \log(xy) = \log x + \log y) \\
&= \sum_{i = 1}^k (-\log_2 p_i) \\ 
&= \sum_{i = 1}^k w(e_i).
\end{align*}
$$
- Therefore:
	- **maximise** $\prod p(e)$ - total probability
	- is the same as **minimise** $\sum w(e)$ - total information

Finding the highest transmission probability between every pair of vertices $\iff$ Finding the path of minimum total “information weight” between $u$ and $v$.

---

##### Relationship between information and probability

$$
I(\pi) = -\log_2 p(\pi)
\quad\Longleftrightarrow\quad
p(\pi) = 2^{-I(\pi)}.
$$

$$
p(\pi) = \prod_{i=0}^k p(v_{i-1}, v) \quad \equiv \quad  \sum_{i = 0}^k \big(-\log_2 p(v_{i-1}, v)\big) = I(\pi).
$$


> [!abstraction] 
> Given a weighted graph $G=(V,E)$ on which each edge $(u, v) \in E$ has an associated transmission probability  $p(u, v)$ which is a real number in the range $0 < p(u, v) \leq 1$ that represents the probability that the channel from $u$ to $v$ will not fail. Assume that these probabilities are independent.
> 
> Find the path with the highest transmission probability between two given vertices.

- Prove that for vertices, the "reweighted" value is a nonnegative real number.
 a weighted graph 


Given an undirected and connected graph $G=(V,E)$ with $n$ vertices representing the locations and $m$ edges representing the transmission cables. Each edge $(u, v) \in E$ has an associated transmission probability  $p(u, v)$ which is a real number in the range $0 < p(u, v) \leq 1$ that represents the probability that the cable between $u$ and $v$ will not fail.


We reduce the problem to a standard shortest path problem as follows:

For each edge $(u, v) \in E$, define the weight as

$$w(u, v) = -\log_2 p(u, v),$$

which represents the amount of information transmitted between $u$ and $v$.

Since $0 < p(u, v) \leq 1$, it follows that $\log_2 p(u, v) \leq 0$; therefore

$$w(u, v) = -\log_2 p(u, v) \geq 0.$$ 

Hence the graph has nonnegative weights on all edges.

We first claim that between every pair of vertices, the maximum transmission probability and minimum amount of information transmitted are in one-to-one correspondence. From this claim, we deduce that shortest paths in $G$ with nonnegative weights $w(u, v) = I(u,v)$ corresponds to the paths with maximum transmission probability.

Let $\pi = v_0, v_1, \ldots, v_{k}$ by any path from vertex $v_0$ to vertex $v_k$, where each consecutive pair $(v_{i-1}, v_{i}) \in E$ for $i=0, 1, \ldots, k$. 

The transmission probability of $\pi$ is 

$$
p(\pi) = \prod_{i=0}^k p(v_{i-1}, v).
$$

From part (c), the amount of information transmitted is equal to the sum of information content between each pair of vertices in $\pi$; therefore, $I(\pi)$ corresponds to the sum of edge weights in $\pi$

$$
\begin{align*}
I(\pi) &= -\log_2 \prod_{i=0}^k p(v_{i-1}, v) \\
&= -\sum_{i = 0}^k \log_2 p(v_{i-1}, v)   && (\log(xy) = \log x + \log y) \\
&= \sum_{i = 0}^k \big(-\log_2 p(v_{i-1}, v) \big)
= \sum_{i = 0}^k w(v_{i-1}, v_1) = w(\pi).
\end{align*}
$$

Recall that $-\log_2 x \geq 0 \iff x \in (0, 1]$. Hence for any two paths $\pi_1, \pi_2$, we have the following inequality

$$
p(\pi_1) > p(\pi_2) \iff -\log_2 p(\pi_1) <  -\log_2 p(\pi_2) \iff   w(\pi_1) < w(\pi_2).
$$

This shows that for all pairs of vertices $u, v \in V$, a path $\pi$ from $u$ to $v$ has the maximum transmission probability if and only if $\pi$ also has the minimum information weight.

Finally, if the shortest path between $u$ and $v$ has weight $d(u, v)$, the corresponding maximum transmission probability is $2^{-d(u, v)}$ by noting that
$$
I(\pi) = -\log_2 p(\pi)
\quad\Longleftrightarrow\quad
p(\pi) = 2^{-I(\pi)}.
$$ 

We can, therefore,  compute the maximum probabilities between every pair of distinct locations by finding the shortest paths between all pairs of vertices in $G$ with the Floyd–Warshall algorithm in $O(n^3)$ time. 

Alternatively, since all edge weights are nonnegative, we can run Dijkstra's algorithm $n$ times, once with each vertex as the source. This yields a total running time of  $O(nm \log n)$, which is asymptotically faster the Floyd-Warshall algorithm if the graph is sparse.






##### Time Complexity 

We can, therefore, compute the shortest paths between all pairs of vertices in $G$ with the Floyd–Warshall algorithm in $O(n^3)$ time. 

Alternatively, since all edge weights are nonnegative, we can run Dijkstra's algorithm $n$ times, once with each vertex as the source. If the min-priority queue in Dijkstra's algorithm is implemented by a Fibonacci heap, the algorithm runs in $O(n^2 \log n + nm)$; otherwise the binary min-heap implementation yields a running time of  $O(nm \log n)$, which is still asymptotically faster the Floyd-Warshall algorithm if the graph is sparse.



---

Reweighting

If $G$ has negative-weight edges but no negative-weight cycles, we can apply 

- For all pairs of vertices $u, v \in V$, a path $p$ is a shortest from $u$ to $v$ using weight function $w$ if and only if $p$ is also a shortest path from $u$ to $v$ using weight function $\hat{w}$
- For all edges $(u, v)$, the new weight $\hat{w}(u, v)$ is nonnegative.


> [!important]
> Why the reduction is valid
> 
> 1. Every path probability is a **product** of edge probabilities (independence).  
> 2. $-\log_2$ turns products into **sums**.  
> 3. $-\log_2(\cdot)$ is **strictly decreasing** on $(0,1]$, so a path with **higher** probability corresponds to a path with **lower** information.  
> 4. Therefore, **max-probability paths and min-information paths are in one-to-one correspondence**.  
> 
> Hence, solving the min-information version solves the original problem.

---

<b>Problem</b>

Given a weighted, directed graph $G=(V,E)$ on which each edge $(u, v) \in E$ has an associated transmission probability 

$$w(u \to v) = -\log_2 p(u, v),$$

which is a real number in the range $0 \leq w(u, v) \leq 1$ that represents the  


For all $1 \le i, j \le n$ and $0 \le k \le n$, let $\operatorname{opt}(i, j, k)$ be the weight of a shortest path from $v_i$ to $v_j$ using only $v_1, v_2, \ldots, v_k$ as intermediate vertices.

For any pair of vertices $i, j \in V$, consider all paths from $i$ to $j$ with all intermediate vertices in the set $\{1, 2, \ldots k\}$. Let $p$ be a minimum-weight path from among them.

For every cable $(s, t)$ from location $s$ to $t$ with transmission probability $p(s, t)$, define the information between every pair of distinct locations as $-\log_2 p(s, t)$ for all $s \leq 1, t \leq n$. 
Recall that $\log x + \log y = \log(xy)$ and  $\log x < 0 \iff x \in (0, 1)$.
A connected undirected graph $G= (V,E)$ with $|V| = n$ locations and $|E| = m$ transmission cables. 




The weight $w(p)$ of path $p = v_0, v_1, \ldots, v_k$ from vertex $v_0$ to vertex $v_k$, is the sum of weights of its constituent edges:

$$
w(p) =  \sum_{i=1}^k w(v_{i-1}, v_i)
= -\sum_{(u, v) \in E} \log_2 p(e)
= -\log_2 \left(\prod_{e \in \pi} p(e)\right).
$$



<b>Subproblems</b>  
Let  
$$\text{dist}_k[i,j]$$  
be the minimum total information to go from vertex $i$ to vertex $j$ using only intermediate vertices from the set $\{1,2,\dots,k\}$**.

<b>Base cases</b>
For $k = 0$:
- $\text{dist}_0[i,i] = 0$ for all $i$,
- $\text{dist}_0[i,j] = w(i,j)$ if there is an edge,
- $\text{dist}_0[i,j] = +\infty$ otherwise.

<b>Recurrence (optimal substructure)</b>
When we allow vertex $k$ as an extra intermediate, any optimal $i \to j$ path either:
- does **not** go through $k$: cost $\text{dist}_{k-1}[i,j]$, or  
- **does** go through $k$: cost $\text{dist}_{k-1}[i,k] + \text{dist}_{k-1}[k,j]$.

The recurrence is given by:

$$
\text{dist}_k[i,j]
= \min\big( \text{dist}_{k-1}[i,j],\; \text{dist}_{k-1}[i,k] + \text{dist}_{k-1}[k,j] \big).
$$

<b>Order of computation</b>  

```
for k = 1 to n:
 for i = 1 to n:  
  for j = 1 to n: 
	  apply the recurrence
```

At the end, $\text{dist}_n[i,j]$ is the **minimum information** from $i$ to $j$.

<b>Algorithm</b>  

We restated the problem in terms of **information** to use Floyd–Warshall, but Thomas actually wants **probabilities**.  

If $\text{dist}[i,j]$ is the minimal information between $i$ and $j$, then the corresponding **maximum probability** is  

$$
P^\star(i,j) = 2^{-\text{dist}[i,j]}.
$$  

So after the DP finishes, just apply this formula to each pair.

---
We can reduce this problem to the all-pairs shortest paths on a weighted graph with weights $w(u,v)$ as follows: 

We convert each edge probability $p(u,v)$ to an information weight  
$$
w(u,v) = -\log_2 p(u,v).
$$  
For any path, the information is the **sum** of its edge informations, while the probability is the **product** of edge probabilities. Since $-\log_2$ is strictly decreasing and  
$$
-\log_2 \Big(\prod p_i\Big) = \sum -\log_2 p_i,
$$  
a path has maximum probability if and only if it has minimum total information. Therefore, the problem reduces to **all-pairs shortest paths** on a weighted graph with weights $w(u,v)$.

We can solve this with the Floyd–Warshall algorithm:
$$
\text{dist}[i,j] = \min\big(\text{dist}[i,j],\; \text{dist}[i,k] + \text{dist}[k,j]\big) 
\quad \text{for } k = 1, \dots, n.
$$

At the end, $\text{dist}[i,j]$ is the minimum information from $i$ to $j$, so the **maximum** transmission probability is  
$$
P^\star(i,j) = 2^{-\text{dist}[i,j]}.
$$

Floyd–Warshall runs in $O(n^3)$ time and $O(n^2)$ space.


---






